{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with Lhotse\n",
    "\n",
    "This notebook provides the training script used in our research paper.\n",
    "\n",
    "It utilizes Lhotse for data preprocessing and ESPnet2 for training.\n",
    "This notebook also supports online fine-tuning.\n",
    "\n",
    "In this notebook, we will use the LoRA adapter to fine-tune the pre-trained OWSM model.\n",
    "Basically this notebook is almost the same as the `train.ipynb` except for the custom dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import librosa\n",
    "from pathlib import Path\n",
    "from espnet2.layers.create_adapter_fn import create_lora_adapter\n",
    "import argparse\n",
    "\n",
    "# import lhotse related modules\n",
    "from lhotse import CutSet\n",
    "from lhotse.dataset import AudioSamples\n",
    "from lhotse.recipes import prepare_librispeech\n",
    "\n",
    "import espnetez as ez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define the paths to your dumped files and other important training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to project directories and pre-trained model\n",
    "BASE_DIR = Path(\"path/to/egs2/librispeech_100/ez1\")\n",
    "\n",
    "STATS_DIR = f\"{BASE_DIR}/exp/stats_owsm_base_finetune\"\n",
    "EXP_DIR = f\"{BASE_DIR}/exp/owsm_base_finetune\"\n",
    "\n",
    "FINETUNE_MODEL = \"espnet/owsm_v3.1_ebf_base\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a custom dataset class to retrieve data from the dumped files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class to load data from preprocessed files\n",
    "class CustomDataset:\n",
    "    def __init__(self, manifest, apply_augmentation=False, p=0.3):\n",
    "        self.apply_augmentation = apply_augmentation\n",
    "        self.length = len(manifest['recordings'])\n",
    "        self.cuts = CutSet.from_manifests(**manifest).trim_to_supervisions()\n",
    "        self.p = p\n",
    "        self.audio_samples = AudioSamples()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        monocut = self.cuts[idx]\n",
    "        text = monocut.supervisions[0].text\n",
    "        if self.apply_augmentation:\n",
    "            if random.random() < self.p:\n",
    "                monocut = monocut.perturb_speed(\n",
    "                    factor=random.choice([0.9])\n",
    "                )\n",
    "            if random.random() < self.p:\n",
    "                monocut = monocut.perturb_volume(\n",
    "                    factor=random.uniform(0.125, 2.0)\n",
    "                )\n",
    "            if random.random() < self.p:\n",
    "                monocut = monocut.perturb_tempo(\n",
    "                    factor=random.choice([0.9])\n",
    "                )\n",
    "        \n",
    "        return {\n",
    "            'speech': self.audio_samples([monocut])[0][0],\n",
    "            'text': text,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the OWSM models were trained on lowercase text, we need to convert all text data to lowercase. \n",
    "\n",
    "Next, we'll define the training configuration. This involves using the configuration from a pre-trained OWSM model as a base and then adding our own custom configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained OWSM model configuration for tokenizer, converter, and base training configuration\n",
    "from espnet2.bin.s2t_inference import Speech2Text\n",
    "\n",
    "pretrained_model = Speech2Text.from_pretrained(\n",
    "    FINETUNE_MODEL,\n",
    "    # category_sym=\"<en>\",  # Comment out if not used\n",
    "    beam_size=10,\n",
    "    device=\"cpu\"\n",
    ")\n",
    "tokenizer = pretrained_model.tokenizer\n",
    "converter = pretrained_model.converter\n",
    "training_config = vars(pretrained_model.s2t_train_args)\n",
    "del pretrained_model\n",
    "\n",
    "# Update finetuning configuration from a YAML file (likely user-defined)\n",
    "finetune_config = ez.config.update_finetune_config(\n",
    "    \"s2t\",\n",
    "    training_config,\n",
    "    \"path/to/your/finetune/config.yaml\"\n",
    ")\n",
    "finetune_config['multiple_iterator'] = False  # Set training parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define `data_info` to connect our custom dataset with the ESPnet dataloader. This helps the dataloader understand how to process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data_info to connect custom dataset with ESPnet dataloader\n",
    "def tokenize(text):\n",
    "    return np.array(converter.tokens2ids(tokenizer.text2tokens(text)))\n",
    "\n",
    "\n",
    "data_info = {\n",
    "    \"speech\": lambda d : d['speech'].numpy(), # audio is already loaded in lhotse.\n",
    "    \"text\": lambda d : tokenize(f\"{d['text'].lower()}\"),\n",
    "    \"text_prev\": lambda d : tokenize(\"<na>\"),\n",
    "    \"text_ctc\": lambda d : tokenize(d['text'].lower()),\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a function to prepare the model for fine-tuning. While you can define a custom model here, this notebook uses the pre-trained OWSM model directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def build_model_fn(args):\n",
    "    pretrained_model = Speech2Text.from_pretrained(\n",
    "        FINETUNE_MODEL,\n",
    "        beam_size=10,\n",
    "    )\n",
    "    model = pretrained_model.s2t_model\n",
    "    model.train()\n",
    "    print(f'Trainable parameters: {count_parameters(model)}')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're almost ready!\n",
    "Now, let's prepare the datasets and convert them into the format expected by ESPnet's dataloader. The dataloader relies on ESPnetDataset objects to process and feed data during training.\n",
    "\n",
    "We are using the Lhotse library to prepare the LibriSpeech dataset, but you can use your own manifest file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librispeech_100_path = \"path/to/LibriSpeech\"\n",
    "libri = prepare_librispeech(librispeech_100_path)\n",
    "\n",
    "train_dataset = CustomDataset(libri[\"train-clean-100\"], apply_augmentation=True)\n",
    "dev_dataset = CustomDataset(libri[\"dev-clean\"], apply_augmentation=False)\n",
    "\n",
    "train_dataset = ez.dataset.ESPnetEZDataset(train_dataset, data_info=data_info)\n",
    "dev_dataset = ez.dataset.ESPnetEZDataset(dev_dataset, data_info=data_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that everything is set up, let's start the training process!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ez.Trainer(\n",
    "    task=\"s2t\",\n",
    "    train_config=finetune_config,\n",
    "    train_dataset=train_dataset,\n",
    "    valid_dataset=dev_dataset,\n",
    "    data_info=data_info,\n",
    "    build_model_fn=build_model_fn,\n",
    "    output_dir=EXP_DIR,\n",
    "    stats_dir=STATS_DIR,\n",
    "    ngpu=1,\n",
    ")\n",
    "trainer.collect_stats()\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
